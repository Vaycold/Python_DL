{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNq2Xhw1onGu"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QADtj-QSou4G"
      },
      "source": [
        "seed = 1\n",
        "lr = 1e-3\n",
        "momentum = 0.5\n",
        "batch_size = 64\n",
        "test_batch_size = 64\n",
        "epochs = 5\n",
        "no_cuda = False\n",
        "log_interval = 100"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwowK2RMpAX9"
      },
      "source": [
        "# Model\n",
        "\n",
        "class Net(nn.Module) :\n",
        "    def __init__(self) :\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,20,5,1)\n",
        "        self.conv2 = nn.Conv2d(20,50,5,1)\n",
        "        self.fc1   = nn.Linear(4*4*50, 500)\n",
        "        self.fc2   = nn.Linear(500,10)\n",
        "\n",
        "    def forward(self, x) :\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2) \n",
        "        x = x.view(-1,4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJRL1IJ1p45T",
        "outputId": "ccafec17-5322-4ae6-f708-18a660af94ce"
      },
      "source": [
        "drive.mount('/content/MyDrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3L1iDKdreff"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqRm6rAzqjy_"
      },
      "source": [
        "google_path = '/content/MyDrive/MyDrive/fastcampus/DL_300/이미지분석/dataset/mnist_png'\n",
        "# os.listdir('MyDrive/MyDrive/fastcampus/DL_300/이미지분석/dataset/mnist_png')\n",
        "os.chdir(google_path)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4j-5hXeqlx2",
        "outputId": "e3ed72d4-c2b2-4513-e4ce-c549d4354608"
      },
      "source": [
        "os.listdir('training')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3', '7', '9', '5', '8', '2', '4', '6', '0', '1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mkaeV5Rps6qP",
        "outputId": "f01abcbf-afa6-4200-a00d-90e96240e844"
      },
      "source": [
        "os.listdir()[1]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'training'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uknTGu5Arb8_"
      },
      "source": [
        "train_dir = google_path + '/' + os.listdir()[1]\n",
        "test_dir  = google_path + '/' + os.listdir()[0]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1itqDRGftTkR"
      },
      "source": [
        "torch.manual_seed(seed)\n",
        "\n",
        "use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o-lgr6cu5xp",
        "outputId": "d2808791-28f0-41b1-fb7e-2dd00c07cb3d"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99unJK1kvJME"
      },
      "source": [
        "train_dataset = datasets.ImageFolder(root = train_dir, # torch로 불러오면 gray scale이 되지 않기 떄문에 input에 채널을 3으로 바꿔준다.\n",
        "                                     transform = transforms.Compose([\n",
        "                                                        transforms.ToTensor(),\n",
        "                                                        transforms.Normalize((0.1307,),(0.3081,))\n",
        "                                     ]))    "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jmn_2Aawo2O"
      },
      "source": [
        "test_dataset = datasets.ImageFolder(root = test_dir, # torch로 불러오면 gray scale이 되지 않기 떄문에 input에 채널을 3으로 바꿔준다.\n",
        "                                     transform = transforms.Compose([\n",
        "                                                        transforms.ToTensor(),\n",
        "                                                        transforms.Normalize((0.1307,),(0.3081,))\n",
        "                                     ]))  "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6dmfvtxxI5D",
        "outputId": "2e4342e1-dde1-4a30-ed88-b61f3ebc5e68"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 10000\n",
              "    Root location: /content/MyDrive/MyDrive/fastcampus/DL_300/이미지분석/dataset/mnist_png/testing\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}