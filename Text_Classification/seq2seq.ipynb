{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPRjuIsk57zJZ5NOuYTzn64",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaycold/Python_DL/blob/main/Text_Classification/seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_xUXtfdNWSb"
      },
      "source": [
        "## Goal\n",
        "   - Seq2Seq model\n",
        "   - word embedding\n",
        "   - time series data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOa8qV4HNl0D"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvmWCZUYLrV9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from IPython.display import Image\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "SEED=34"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqK85Fg0N7HL"
      },
      "source": [
        "# DATA SET\n",
        "import random\n",
        "def make_raw_text(count=50000) :\n",
        "    train_text = []\n",
        "    train_answer = []\n",
        "\n",
        "    for _ in range(count) :\n",
        "        t = random.randint(0,3)\n",
        "        if t == 0 :\n",
        "            a = random.randint(0,10)\n",
        "        else :\n",
        "            a = random.randint(0,100)\n",
        "\n",
        "        if t == 0 :\n",
        "            b = random.randint(0,10)\n",
        "        else :\n",
        "            b = random.randint(0,100)\n",
        "        if random.randint(0,2) == 0 :\n",
        "            train = f'{a} + {b}'\n",
        "            answer = f'{a+b}'\n",
        "        else :\n",
        "            train = f'{a} - {b}'\n",
        "            answer = f'{a - b}'\n",
        "        train_text.append(train)\n",
        "        train_answer.append(answer)\n",
        "    return train_text, train_answer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2c9itQ_5QCVn"
      },
      "source": [
        "train_text, train_answer = make_raw_text()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Npfu8ExsRQbX",
        "outputId": "15014434-3a1a-49f0-acd0-f54942dedd5d"
      },
      "source": [
        "print(train_text[:10], '\\n',train_answer[:10])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['80 + 85', '8 - 81', '6 + 10', '58 - 53', '71 - 41', '87 - 76', '71 + 26', '38 + 40', '28 - 9', '5 - 10'] \n",
            " ['165', '-73', '16', '5', '30', '11', '97', '78', '19', '-5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPdfrBX0RaO4",
        "outputId": "b44dadb8-b7fa-4c7f-a8ea-3c7bf1dfa8fb"
      },
      "source": [
        "train_text[0], train_answer[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('80 + 85', '165')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWjwqlEUR3ii"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4juQT1tR91t",
        "outputId": "0b741539-68a3-4e48-87d1-2af907f45067"
      },
      "source": [
        "# Bag of Words \n",
        "# train_text, train_answer 에 나오는 모든 token을 [token , id ] 형태로 변경 // + : 10, - : 11, PAD : 12, EOS : 13\n",
        "vocab= {str(i) : i for i in range(10)}\n",
        "vocab.update(\n",
        "    { \"+\" : 10,\n",
        "      \"-\" : 11, \n",
        "      \"PAD\" : 12,\n",
        "      \"EOS\" : 13}\n",
        ")\n",
        "vocab"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'+': 10,\n",
              " '-': 11,\n",
              " '0': 0,\n",
              " '1': 1,\n",
              " '2': 2,\n",
              " '3': 3,\n",
              " '4': 4,\n",
              " '5': 5,\n",
              " '6': 6,\n",
              " '7': 7,\n",
              " '8': 8,\n",
              " '9': 9,\n",
              " 'EOS': 13,\n",
              " 'PAD': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO9dJewrU048",
        "outputId": "043d45c9-b9fe-4b66-eaea-a82290fb4d0a"
      },
      "source": [
        "# 위 vocab의 역형태 \n",
        "invocab = { v:k for k,v in vocab.items()}\n",
        "invocab"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '0',\n",
              " 1: '1',\n",
              " 2: '2',\n",
              " 3: '3',\n",
              " 4: '4',\n",
              " 5: '5',\n",
              " 6: '6',\n",
              " 7: '7',\n",
              " 8: '8',\n",
              " 9: '9',\n",
              " 10: '+',\n",
              " 11: '-',\n",
              " 12: 'PAD',\n",
              " 13: 'EOS'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6SlT7PaR9xq"
      },
      "source": [
        "# bow형태로 변경 // EOS : End of Sentence\n",
        "def plain2bow(text, vocab) :\n",
        "    return np.array([vocab[ch] for word in text.split() for ch in word] + [vocab['EOS']])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjdlsCKsR9vT"
      },
      "source": [
        "train_bow_text = [plain2bow(text, vocab) for text in train_text]\n",
        "train_bow_answer = [plain2bow(text, vocab) for text in train_answer]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-0Dn0oxR9s1",
        "outputId": "10c5ff5c-028d-4ab1-81e3-2896fdc968f4"
      },
      "source": [
        "train_bow_text[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 8,  0, 10,  8,  5, 13]),\n",
              " array([ 8, 11,  8,  1, 13]),\n",
              " array([ 6, 10,  1,  0, 13]),\n",
              " array([ 5,  8, 11,  5,  3, 13]),\n",
              " array([ 7,  1, 11,  4,  1, 13]),\n",
              " array([ 8,  7, 11,  7,  6, 13]),\n",
              " array([ 7,  1, 10,  2,  6, 13]),\n",
              " array([ 3,  8, 10,  4,  0, 13]),\n",
              " array([ 2,  8, 11,  9, 13]),\n",
              " array([ 5, 11,  1,  0, 13])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vWhukA3R9qs"
      },
      "source": [
        "# padding 을 추가하여 완전한 np.array로 만들자\n",
        "train_bow_text=tf.keras.preprocessing.sequence.pad_sequences(train_bow_text, value = vocab['PAD'])\n",
        "train_bow_answer=tf.keras.preprocessing.sequence.pad_sequences(train_bow_answer, padding = 'post' ,value = vocab['PAD'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpnBX4YrR9oa",
        "outputId": "2ffa354a-b8ee-49c0-90af-1891fff47b2f"
      },
      "source": [
        "train_bow_text.shape, train_bow_answer.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 8), (50000, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWI41q2TR3ij",
        "outputId": "928985cc-e3e0-4b44-acb9-7d46a35446b2"
      },
      "source": [
        "train_bow_text[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12, 12,  8,  0, 10,  8,  5, 13],\n",
              "       [12, 12, 12,  8, 11,  8,  1, 13],\n",
              "       [12, 12, 12,  6, 10,  1,  0, 13],\n",
              "       [12, 12,  5,  8, 11,  5,  3, 13],\n",
              "       [12, 12,  7,  1, 11,  4,  1, 13],\n",
              "       [12, 12,  8,  7, 11,  7,  6, 13],\n",
              "       [12, 12,  7,  1, 10,  2,  6, 13],\n",
              "       [12, 12,  3,  8, 10,  4,  0, 13],\n",
              "       [12, 12, 12,  2,  8, 11,  9, 13],\n",
              "       [12, 12, 12,  5, 11,  1,  0, 13]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Brwp2SLYorD",
        "outputId": "1e528ff8-8808-4ccd-e5fb-54f270ee85d7"
      },
      "source": [
        "train_bow_answer[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  6,  5, 13, 12],\n",
              "       [11,  7,  3, 13, 12],\n",
              "       [ 1,  6, 13, 12, 12],\n",
              "       [ 5, 13, 12, 12, 12],\n",
              "       [ 3,  0, 13, 12, 12],\n",
              "       [ 1,  1, 13, 12, 12],\n",
              "       [ 9,  7, 13, 12, 12],\n",
              "       [ 7,  8, 13, 12, 12],\n",
              "       [ 1,  9, 13, 12, 12],\n",
              "       [11,  5, 13, 12, 12]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7GAHsXAR80f"
      },
      "source": [
        "## Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1hhvEe-pbwI",
        "outputId": "db9ce9eb-481e-4a30-f41d-140a74950d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def splitdata(data, rate) :\n",
        "    return int(len(data) * rate)\n",
        "bound = splitdata(train_bow_text, 0.98)\n",
        "print(bound)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6glOTOKOR80h"
      },
      "source": [
        "train_data_bow = train_bow_text[:bound]\n",
        "train_answer_bow = train_bow_answer[:bound]\n",
        "\n",
        "test_data_bow = train_bow_text[bound:]\n",
        "test_answer_bow = train_bow_answer[bound:]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WziL0bomR8-N"
      },
      "source": [
        "## Visualizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqRiTJJoR8-N",
        "outputId": "aa36c728-a839-4896-dc80-0ea1eda818dc"
      },
      "source": [
        "# token 분포\n",
        "np.unique(train_data_bow)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RPRagmIqZy4"
      },
      "source": [
        "digits, count = np.unique(train_data_bow, return_counts=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_luSpN0PqZwg",
        "outputId": "ee0cb5af-c8b2-4e71-eb65-d73a9adc6216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "digits, count"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
              "       dtype=int32),\n",
              " array([ 12971,  19676,  16625,  16923,  16729,  16873,  16811,  16839,\n",
              "         16955,  16899,  16314,  32686, 126699,  49000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5JhhKAeqZuJ",
        "outputId": "4e6eb0cf-726d-403b-843a-c896e142730f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "plt.bar(digits[:10],count[:10])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0qKlOSwR9BK"
      },
      "source": [
        "## Seq2Seq 입출력 보정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvnR3tkPR9BL",
        "outputId": "3a47c3b6-218a-4407-af88-0343cf2e21fa"
      },
      "source": [
        "train_answer_bow.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upBku6DNrYL5",
        "outputId": "f3aa8873-0588-477a-c598-61c1868903fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data_bow.shape, train_answer_bow.shape, test_data_bow.shape, test_answer_bow.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49000, 8), (49000, 5), (1000, 8), (1000, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJbLahxXrYKG",
        "outputId": "1b7257d2-ad7f-41cd-da20-f195f27ddcd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 밑의 것을 한 칸씩 당길 것임.\n",
        "# !!!!!!!!!!!!!!!!!중요한 건 지금 하는건 출력 쪽 보정임!!\n",
        "train_answer_bow[:2]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  6,  5, 13, 12],\n",
              "       [11,  7,  3, 13, 12]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlk4QmSwrYHU",
        "outputId": "7875eec0-fa99-4363-dd65-2601b03b32e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 당기고 넣을 값을 만들어주자\n",
        "ONE = np.ones((train_answer_bow.shape[0],1)) * vocab['PAD'] # len(data) * 1 짜리 만들고 그 값을 전부 PAD값으로 채움.\n",
        "print(ONE, '\\n','\\n','shape :', ONE.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[12.]\n",
            " [12.]\n",
            " [12.]\n",
            " ...\n",
            " [12.]\n",
            " [12.]\n",
            " [12.]] \n",
            " \n",
            " shape : (49000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGJyRu90rYE9",
        "outputId": "0cd6f775-3338-44d8-e758-bded5f2501e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_answer_bow[...,:-1][:2] # 맨마지막꺼를 없애고 저 1x12 짜리를 맨 앞에다가 넣는 느낌임."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  6,  5, 13],\n",
              "       [11,  7,  3, 13]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNOgpg9vMPq9",
        "outputId": "16a0d907-f856-40a5-c971-24064c4883af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_shift_answer_bow = np.concatenate(\n",
        "    [ ONE, train_answer_bow[...,:-1]] , axis=1\n",
        ")\n",
        "\n",
        "test_shift_answer_bow = np.concatenate(\n",
        "    [ np.ones((test_answer_bow.shape[0],1)) * vocab['PAD'], test_answer_bow[...,:-1]] , axis=1\n",
        ")\n",
        "\n",
        "print(train_answer_bow[:5])\n",
        "print(train_shift_answer_bow[:5])\n",
        "\n",
        "print('')\n",
        "\n",
        "print(test_answer_bow[:5])\n",
        "print(test_shift_answer_bow[:5])\n",
        "\n",
        "# 한칸이 땡겨지고 맨앞이 pad로 채워짐\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  6  5 13 12]\n",
            " [11  7  3 13 12]\n",
            " [ 1  6 13 12 12]\n",
            " [ 5 13 12 12 12]\n",
            " [ 3  0 13 12 12]]\n",
            "[[12.  1.  6.  5. 13.]\n",
            " [12. 11.  7.  3. 13.]\n",
            " [12.  1.  6. 13. 12.]\n",
            " [12.  5. 13. 12. 12.]\n",
            " [12.  3.  0. 13. 12.]]\n",
            "\n",
            "[[11  5  4 13 12]\n",
            " [ 8  3 13 12 12]\n",
            " [11  2  7 13 12]\n",
            " [ 6  4 13 12 12]\n",
            " [11  9 13 12 12]]\n",
            "[[12. 11.  5.  4. 13.]\n",
            " [12.  8.  3. 13. 12.]\n",
            " [12. 11.  2.  7. 13.]\n",
            " [12.  6.  4. 13. 12.]\n",
            " [12. 11.  9. 13. 12.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oflnzy1VMPpB",
        "outputId": "06bf3558-8cd2-43f5-f5c3-1a0c88a473ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 정답으로 처리될 train / test_answer_bow를 onehot으로 바꾸는 코드를 작성\n",
        "train_answer_onehot = keras.utils.to_categorical(train_answer_bow, len(vocab))\n",
        "test_answer_onehot  = keras.utils.to_categorical(test_answer_bow, len(vocab))\n",
        "train_answer_onehot.shape, test_answer_onehot.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49000, 5, 14), (1000, 5, 14))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adq-1v6vMPkR",
        "outputId": "143a6dc0-5508-414e-c069-74b95a06c5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# one hot data를 읽을 수 있게 바꿔주자\n",
        "def onehot2txt(onehot) :\n",
        "    return \"\".join(invocab[step.argmax()] for step in onehot).replace('EOS','.').replace('PAD','')\n",
        "\n",
        "onehot2txt(train_answer_onehot[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'165.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwAXMYUMPhN",
        "outputId": "6831fcea-456d-4011-8124-86d552812800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "train_text[0]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'80 + 85'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLQ3aEzKPjfd",
        "outputId": "46887f6d-2a46-432b-9c16-4fef1675779c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# bow를 읽을 수 있게 바꿔주자\n",
        "def bow2txt(bow) :\n",
        "    return ''.join(invocab[step] for step in bow).replace('EOS','.').replace('PAD','')\n",
        "\n",
        "print(train_data_bow[0])\n",
        "print(bow2txt(train_data_bow[0]))\n",
        "print('----------')\n",
        "print(train_shift_answer_bow[0])\n",
        "print(bow2txt(train_shift_answer_bow[0]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[12 12  8  0 10  8  5 13]\n",
            "80+85.\n",
            "----------\n",
            "[12.  1.  6.  5. 13.]\n",
            "165.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDCs7RejR9EW"
      },
      "source": [
        "## Seq2Seq Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL3chckpWH21",
        "outputId": "a921b4c3-7941-4e04-be31-3b253965db17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data_bow.shape, train_shift_answer_bow.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((49000, 8), (49000, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbJKyvPbR9EX"
      },
      "source": [
        "from keras.layers import Input, Embedding, GRU\n",
        "from keras.models import Model\n",
        "def seq2seq() : # model , encoder, decoder 반환\n",
        "    \n",
        "    embedding = Embedding(len(vocab), 5)\n",
        "    \n",
        "    input_x_bow = Input(shape=(8,))\n",
        "    x = embedding(input_x_bow)\n",
        "    z = GRU(16)(x)             # 여기까지가 Encoder 부분\n",
        "\n",
        "    input_y_bow = Input(shape=(5,))\n",
        "    y = embedding(input_y_bow)\n",
        "    gru = GRU(16, return_sequences=True)\n",
        "\n",
        "    y = gru(y, initial_state = z)\n",
        "    \n",
        "    softmax = Dense(len(vocab), activation='softmax')\n",
        "\n",
        "    y = softmax(y)\n",
        "    model = Model([input_x_bow, input_y_bow], y)\n",
        "    model.compile(\n",
        "        loss = 'categorical_crossentropy',\n",
        "        optimizer = 'adam',\n",
        "        metrics = ['accuracy']\n",
        "    )\n",
        "    \n",
        "    encoder = Model(input_x_bow, z) # encoder\n",
        "    \n",
        "    input_y_dec = Input(shape = (1,)) # decoder에 넣을 값\n",
        "    y2 = embedding(input_y_dec)\n",
        "\n",
        "    input_z = Input(shape=(16,))\n",
        "\n",
        "    h2 = gru(y2, initial_state = input_z)\n",
        "    y2 = softmax(h2)\n",
        "\n",
        "    decoder = Model([input_y_dec, input_z], [y2,h2])\n",
        "    return model, encoder, decoder\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jQWyArXVS5D"
      },
      "source": [
        "model, encoder, decoder = seq2seq()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90AltHfcVS29",
        "outputId": "3d248897-5c13-4031-aa7a-e892fca002fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_9 (InputLayer)            [(None, 8)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         multiple             70          input_9[0][0]                    \n",
            "                                                                 input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gru_4 (GRU)                     (None, 16)           1104        embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "gru_5 (GRU)                     multiple             1104        embedding_2[1][0]                \n",
            "                                                                 gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 multiple             238         gru_5[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 2,516\n",
            "Trainable params: 2,516\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTUfaA4oVS09",
        "outputId": "e35c40db-db14-485b-9276-4e4a1f06ab59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        " encoder.summary()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 8)]               0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      multiple                  70        \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 16)                1104      \n",
            "=================================================================\n",
            "Total params: 1,174\n",
            "Trainable params: 1,174\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9uf_f4wVSym",
        "outputId": "9096fda9-d0f6-417e-89bc-65cdd39e139c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "decoder.summary()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         multiple             70          input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_12 (InputLayer)           [(None, 16)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gru_5 (GRU)                     multiple             1104        embedding_2[2][0]                \n",
            "                                                                 input_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 multiple             238         gru_5[1][0]                      \n",
            "==================================================================================================\n",
            "Total params: 1,412\n",
            "Trainable params: 1,412\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nK_n0M-VSwN",
        "outputId": "509afec6-79fe-4f90-9c6c-b983cf538747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "hist = model.fit( [ train_data_bow, train_shift_answer_bow], train_answer_onehot,\n",
        "          validation_data = ([test_data_bow, test_shift_answer_bow], test_answer_onehot),\n",
        "          epochs = 60,\n",
        "          verbose = 1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "1532/1532 [==============================] - 11s 5ms/step - loss: 1.4309 - accuracy: 0.5691 - val_loss: 0.9356 - val_accuracy: 0.6910\n",
            "Epoch 2/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.8867 - accuracy: 0.6942 - val_loss: 0.7838 - val_accuracy: 0.7184\n",
            "Epoch 3/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.7664 - accuracy: 0.7194 - val_loss: 0.7313 - val_accuracy: 0.7284\n",
            "Epoch 4/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.7147 - accuracy: 0.7394 - val_loss: 0.6755 - val_accuracy: 0.7616\n",
            "Epoch 5/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.6591 - accuracy: 0.7650 - val_loss: 0.6233 - val_accuracy: 0.7760\n",
            "Epoch 6/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.6030 - accuracy: 0.7873 - val_loss: 0.5696 - val_accuracy: 0.7962\n",
            "Epoch 7/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.5570 - accuracy: 0.8079 - val_loss: 0.5298 - val_accuracy: 0.8196\n",
            "Epoch 8/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.5236 - accuracy: 0.8196 - val_loss: 0.5002 - val_accuracy: 0.8294\n",
            "Epoch 9/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.4925 - accuracy: 0.8308 - val_loss: 0.4773 - val_accuracy: 0.8352\n",
            "Epoch 10/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.4649 - accuracy: 0.8385 - val_loss: 0.4459 - val_accuracy: 0.8462\n",
            "Epoch 11/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.4419 - accuracy: 0.8436 - val_loss: 0.4318 - val_accuracy: 0.8422\n",
            "Epoch 12/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.4243 - accuracy: 0.8484 - val_loss: 0.4172 - val_accuracy: 0.8496\n",
            "Epoch 13/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.4058 - accuracy: 0.8546 - val_loss: 0.3942 - val_accuracy: 0.8588\n",
            "Epoch 14/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3900 - accuracy: 0.8606 - val_loss: 0.3865 - val_accuracy: 0.8590\n",
            "Epoch 15/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3779 - accuracy: 0.8640 - val_loss: 0.3791 - val_accuracy: 0.8554\n",
            "Epoch 16/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3657 - accuracy: 0.8685 - val_loss: 0.3656 - val_accuracy: 0.8648\n",
            "Epoch 17/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3565 - accuracy: 0.8719 - val_loss: 0.3488 - val_accuracy: 0.8742\n",
            "Epoch 18/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3465 - accuracy: 0.8753 - val_loss: 0.3470 - val_accuracy: 0.8712\n",
            "Epoch 19/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3357 - accuracy: 0.8786 - val_loss: 0.3269 - val_accuracy: 0.8784\n",
            "Epoch 20/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3284 - accuracy: 0.8804 - val_loss: 0.3723 - val_accuracy: 0.8494\n",
            "Epoch 21/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3287 - accuracy: 0.8779 - val_loss: 0.3145 - val_accuracy: 0.8870\n",
            "Epoch 22/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3155 - accuracy: 0.8846 - val_loss: 0.3121 - val_accuracy: 0.8864\n",
            "Epoch 23/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3081 - accuracy: 0.8865 - val_loss: 0.3051 - val_accuracy: 0.8888\n",
            "Epoch 24/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.3007 - accuracy: 0.8909 - val_loss: 0.2962 - val_accuracy: 0.8922\n",
            "Epoch 25/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2962 - accuracy: 0.8919 - val_loss: 0.2890 - val_accuracy: 0.8958\n",
            "Epoch 26/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2914 - accuracy: 0.8922 - val_loss: 0.2883 - val_accuracy: 0.8940\n",
            "Epoch 27/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2900 - accuracy: 0.8930 - val_loss: 0.2853 - val_accuracy: 0.8958\n",
            "Epoch 28/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2844 - accuracy: 0.8950 - val_loss: 0.2781 - val_accuracy: 0.9018\n",
            "Epoch 29/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2813 - accuracy: 0.8959 - val_loss: 0.2803 - val_accuracy: 0.8960\n",
            "Epoch 30/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2753 - accuracy: 0.8981 - val_loss: 0.2838 - val_accuracy: 0.8920\n",
            "Epoch 31/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2736 - accuracy: 0.8986 - val_loss: 0.2626 - val_accuracy: 0.9068\n",
            "Epoch 32/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2680 - accuracy: 0.9006 - val_loss: 0.3106 - val_accuracy: 0.8680\n",
            "Epoch 33/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2652 - accuracy: 0.9011 - val_loss: 0.2690 - val_accuracy: 0.8952\n",
            "Epoch 34/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2615 - accuracy: 0.9031 - val_loss: 0.2572 - val_accuracy: 0.9042\n",
            "Epoch 35/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2584 - accuracy: 0.9036 - val_loss: 0.2666 - val_accuracy: 0.8934\n",
            "Epoch 36/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2558 - accuracy: 0.9049 - val_loss: 0.2528 - val_accuracy: 0.9078\n",
            "Epoch 37/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2516 - accuracy: 0.9068 - val_loss: 0.2575 - val_accuracy: 0.9050\n",
            "Epoch 38/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2536 - accuracy: 0.9037 - val_loss: 0.2462 - val_accuracy: 0.9126\n",
            "Epoch 39/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2493 - accuracy: 0.9066 - val_loss: 0.2382 - val_accuracy: 0.9178\n",
            "Epoch 40/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2443 - accuracy: 0.9102 - val_loss: 0.2433 - val_accuracy: 0.9064\n",
            "Epoch 41/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2424 - accuracy: 0.9105 - val_loss: 0.2724 - val_accuracy: 0.8910\n",
            "Epoch 42/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2433 - accuracy: 0.9071 - val_loss: 0.2312 - val_accuracy: 0.9164\n",
            "Epoch 43/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2381 - accuracy: 0.9113 - val_loss: 0.2427 - val_accuracy: 0.9110\n",
            "Epoch 44/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2375 - accuracy: 0.9104 - val_loss: 0.2276 - val_accuracy: 0.9246\n",
            "Epoch 45/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2364 - accuracy: 0.9119 - val_loss: 0.2488 - val_accuracy: 0.8966\n",
            "Epoch 46/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2350 - accuracy: 0.9108 - val_loss: 0.2353 - val_accuracy: 0.9086\n",
            "Epoch 47/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2299 - accuracy: 0.9143 - val_loss: 0.2347 - val_accuracy: 0.9098\n",
            "Epoch 48/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2278 - accuracy: 0.9157 - val_loss: 0.2175 - val_accuracy: 0.9250\n",
            "Epoch 49/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2253 - accuracy: 0.9159 - val_loss: 0.2208 - val_accuracy: 0.9220\n",
            "Epoch 50/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2235 - accuracy: 0.9163 - val_loss: 0.2553 - val_accuracy: 0.8916\n",
            "Epoch 51/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2297 - accuracy: 0.9124 - val_loss: 0.2233 - val_accuracy: 0.9184\n",
            "Epoch 52/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2234 - accuracy: 0.9160 - val_loss: 0.2299 - val_accuracy: 0.9088\n",
            "Epoch 53/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2234 - accuracy: 0.9157 - val_loss: 0.2201 - val_accuracy: 0.9176\n",
            "Epoch 54/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2204 - accuracy: 0.9168 - val_loss: 0.2782 - val_accuracy: 0.8838\n",
            "Epoch 55/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2175 - accuracy: 0.9184 - val_loss: 0.2094 - val_accuracy: 0.9278\n",
            "Epoch 56/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2154 - accuracy: 0.9183 - val_loss: 0.2045 - val_accuracy: 0.9300\n",
            "Epoch 57/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2152 - accuracy: 0.9215 - val_loss: 0.2051 - val_accuracy: 0.9274\n",
            "Epoch 58/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2112 - accuracy: 0.9228 - val_loss: 0.2023 - val_accuracy: 0.9318\n",
            "Epoch 59/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2123 - accuracy: 0.9214 - val_loss: 0.2059 - val_accuracy: 0.9290\n",
            "Epoch 60/60\n",
            "1532/1532 [==============================] - 8s 5ms/step - loss: 0.2102 - accuracy: 0.9221 - val_loss: 0.2057 - val_accuracy: 0.9240\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTKMDWxyVSAe"
      },
      "source": [
        "## Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcQOBn7qVSAn",
        "outputId": "6acdef28-76d3-482d-96d4-8a035380fc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Encoder에 bow 주입, z출력 ex)\n",
        "bow = plain2bow('3+1', vocab)\n",
        "print(bow)\n",
        "bow = tf.keras.preprocessing.sequence.pad_sequences(bow[np.newaxis,:], value = vocab['PAD'], maxlen=8)\n",
        "z = encoder(bow)\n",
        "\n",
        "print(bow.shape, bow)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 3 10  1 13]\n",
            "(1, 8) [[12 12 12 12  3 10  1 13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u51MNNgxds5e",
        "outputId": "a6f768e6-8151-4dcf-ee3c-5425d5eb9cd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "z"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
              "array([[-0.99210143,  0.92562205, -0.8740471 ,  0.72899145,  0.99550486,\n",
              "         0.8101876 ,  0.06003232, -0.977211  , -0.63005215,  0.72793174,\n",
              "        -0.9369781 , -0.8989187 ,  0.81851137,  0.6828601 ,  0.4931614 ,\n",
              "        -0.11095364]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0ivylEcds3c",
        "outputId": "a0dddaad-fb26-4b24-e401-85737438a07b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# z와 PAD를 이용하여 첫 번째 DECODER 값 획득 \n",
        "init = np.array([vocab['PAD']])\n",
        "first_pred, first_z = decoder([init,z])\n",
        "print(first_z)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0.95884705  0.07760151 -0.8376278   0.9983256  -0.98732233\n",
            "    0.81391585  0.99850273  0.5048748   0.9427187   0.3953884\n",
            "   -0.29185644  0.99994785  0.9997164   0.37211376 -0.24106151\n",
            "   -0.623957  ]]], shape=(1, 1, 16), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8F9gygYds1C",
        "outputId": "07aaca41-f805-4f1c-e7e2-f4f83d420a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(first_pred)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[3.6102062e-08 4.5978177e-09 3.7282468e-06 5.3687219e-02 6.2058216e-01\n",
            "   3.2279032e-01 2.9330163e-03 3.4229679e-06 2.4685376e-09 2.9132384e-14\n",
            "   3.3514897e-12 1.9582383e-24 3.8040280e-08 9.2832435e-09]]], shape=(1, 1, 14), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83C_9ET1dsy0",
        "outputId": "8c483fb4-80c1-464c-e1b5-008b30a5e4f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 가장 큰 값의 index를 이용하여 문자로 decoding\n",
        "first_pred.numpy().argmax()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TOr63MUfyk-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq0mS_i2fyi3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFiPMU-cfyg0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7HgZql2fyec"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM7c3C23dswm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrJNpXnnVSXN"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrpf66ofVSXN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}